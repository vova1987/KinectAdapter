{"name":"Kinectadapter.github.io","tagline":"XBMC Kinect Adapter","body":"### Welcome to XBMC Kinect Adapter Git Page!\r\nThis page contains all you need yo know on this amazing project!\r\nYou will find simple usage instructions as well as code snippets to help you create and detect your own Gestures!\r\n\r\n### XBMC What?\r\nXBMC is the most widespread open source solution for home entertainment. XBMC lets you control your home theater and adds cool features and custom plugins to enhance your experience. XBMC allows you to control its simple and intuitive interface using any kind of input device - keyboard, mouse, remote, cellphone, etc. BUT - what if you want something even better? even easier? \r\n\r\n### Kinect Who?\r\nKinect is a M$ developed device used mainly in the XBOX gaming platform to detect user position and orientation. It is a cutting-edge technology just waiting to be exploited...\r\n\r\n### XBMC Kinect Adapter\r\nThis is our little project. Our goal is to enable you to control your XBMC using your Kinect device. Use your hands and voice to tell the TV what to do! no more complex remote controls and cumbersome gaming pads. All you need to do is wave your hand XBMC will follow.\r\n\r\n### Installation instructions\r\nJust download the bin directory from the above path and extract it locally on your XBMC PC. Turn on the Kinect and fire up the app. You are ready to GO!\r\n\r\n### Gesture to Command mapping\r\nThe mapping of all availble gestures to XBMC commands is dynamic. Use the provided XML to define your own mappings. The structure of a mapping is as follows:\r\n`<GestureCommandPair>\r\n    <Gesture Type=\"Physical\">TheIdOfYourGesture</Gesture>\r\n    <Command Type=\"KbCommand\">KbButtonToSendToXBMC</Command>\r\n  </GestureCommandPair>`\r\nAs you can see, all you need to do is to add such an elemnt to the xml. if the Gesture ID exists (i.e. there is a class implementing it) it will be mapped to the given XBMC KB command.\r\nSee the XBMC documentation to find all available KB commands.\r\n* You can also add voice gestures by simply setting the tyoe to 'Voice' and entering any word as the gesture ID. Kinect will try and identify this word for you!\r\n\r\n### Implementing a new Gesture\r\nIf you really want to go pro and implement your own custom gestures, here are the steps:\r\n1. For each segment of your gesture, create a new class that implements `IGestureSegment`. Implement the only method of the interface: `CheckGesture()`. This method will be called to determine, based on your criteria, is this segment valid. You have all the Skeleton and interaction data to your disposal. For examples, see the segments already implemented in our project.\r\n2. Add a new class that implements `ICompositeGesture`. Implement the two methods: one to return a unique gesture ID and the second to return a list of Segments for this gesture. Note: The Segments you create are reusable! you can use the same segments to implement different gestures. For such an example - see the WaveLeft/WaveRight gesture classes: they implement a gesture by concatenating the same segments a few times. Make sure the class you created is placed in the `KinectAdapter.Fizbin.Gestures` namespace.\r\n3. Open `GestureToCommand.xml` and add a new mapping from your gesture(use the id returned by the `ICompositeGesture `interface) to any XBMC command. The type of your gesture should be 'Physical'.\r\n4. That's it! the class you created will be dynamically loaded and the command applied according to the xml mapping.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}